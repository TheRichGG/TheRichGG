{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRichGG/TheRichGG/blob/main/fooocus_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "245aec31-9315-4f16-d442-87dd6c762f18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/5.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.17.0\n",
            "    Uninstalling pygit2-1.17.0:\n",
            "      Successfully uninstalled pygit2-1.17.0\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6725, done.\u001b[K\n",
            "remote: Total 6725 (delta 0), reused 0 (delta 0), pack-reused 6725 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6725/6725), 33.36 MiB | 31.25 MiB/s, done.\n",
            "Resolving deltas: 100% (3837/3837), done.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 21.2MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 16.4MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 166MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:01<00:00, 248MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:40<00:00, 177MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 279MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12979 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://e8328f7161f3f14b20.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "2025-03-19 00:53:38.497783: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742345618.765622    1699 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742345618.837014    1699 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-19 00:53:39.416415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 634\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://e8328f7161f3f14b20.gradio.live\n",
            "Loaded preset: /content/Fooocus/presets/anime.json\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/animaPencilXL_v500.safetensors\" to /content/Fooocus/models/checkpoints/animaPencilXL_v500.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [00:49<00:00, 139MB/s]\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6354345002657102622\n",
            "[Parameters] CFG = 6\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.85 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/animaPencilXL_v500.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/animaPencilXL_v500.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, cute, intricate, highly endowed, holy sacred beautiful, dramatic shining light, stunning, mystical, shiny, elite, sharp focus, magical dazzling, spiritual illumination, rich deep vibrant colors, ambient cinematic surreal atmosphere, dynamic background, creative, positive magic, pure, attractive, calm, healing, flowing, complex\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, intricate, stunning, highly detailed, artistic, light, divine, holy, sharp focus, original, cute, fine detail, bright colors, beautiful, amazing, fabulous, elegant, flawless, complex, dazzling, brilliant, colorful, outstanding, creative, wonderful, pure, attractive, luxury, dramatic background, lovely, breathtaking\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 41.91 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "100% 60/60 [00:53<00:00,  1.12it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.19 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 57.19 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "100% 60/60 [00:55<00:00,  1.08it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 58.48 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 115.67 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 157.66 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.04 seconds\n",
            "Loaded preset: /content/Fooocus/presets/sai.json\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors\" to /content/Fooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:24<00:00, 82.0MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0_0.9vae.safetensors\" to /content/Fooocus/models/checkpoints/sd_xl_refiner_1.0_0.9vae.safetensors\n",
            "\n",
            "100% 5.66G/5.66G [01:13<00:00, 82.8MB/s]\n",
            "Loaded preset: /content/Fooocus/presets/sai.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6947453757467039743\n",
            "[Parameters] CFG = 7\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 45\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2560\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "loaded straight to GPU\n",
            "Requested to load SDXLRefiner\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.43 seconds\n",
            "Refiner model loaded: /content/Fooocus/models/checkpoints/sd_xl_refiner_1.0_0.9vae.safetensors\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.5)] for model [/content/Fooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors] with 788 keys at weight 0.5.\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.5)] for model [/content/Fooocus/models/checkpoints/sd_xl_refiner_1.0_0.9vae.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, beautiful, intricate, elegant, highly trained, cute, sacred, sharp focus, bright colors, artistic, surreal, magical, mystical, pristine, attractive, complex, romantic, iconic, fine detail, enhanced, color, clear, aesthetic, inspiring, inspired, lovely, delicate, marvelous, amazing, creative\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, intricate, elegant, highly detailed, extremely cute, divine holy light, creative, beautiful, glowing, sharp focus, stunning, attractive, futuristic, thought, elite, magical, marvelous, gorgeous, flowing, spectacular, bright, colorful, shiny, exquisite, epic background colors, ambient, magic, illuminated, cinematic, scenic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 72.77 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.38 seconds\n",
            " 75% 45/60 [00:40<00:14,  1.06it/s]Requested to load SDXLRefiner\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 60.67 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            " 75% 45/60 [00:40<00:13,  1.10it/s]Requested to load SDXLRefiner\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:56<00:00,  1.07it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 59.56 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 120.23 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 193.05 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.90 seconds\n",
            "Loaded preset: /content/Fooocus/presets/playground_v2.5.json\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/playground-v2.5-1024px-aesthetic.fp16.safetensors\" to /content/Fooocus/models/checkpoints/playground-v2.5-1024px-aesthetic.fp16.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [05:08<00:00, 22.5MB/s]\n",
            "Loaded preset: /content/Fooocus/presets/playground_v2.5.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 143897136906340776\n",
            "[Parameters] CFG = 2\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m - edm_playground_v2.5\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['edm_mean', 'edm_std'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.46 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/playground-v2.5-1024px-aesthetic.fp16.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/playground-v2.5-1024px-aesthetic.fp16.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, intricate, stunning, highly enhanced, romantic, divine holy, dramatic magical, sharp focus, creative, surreal, brilliant, light, magnificent, elegant, luxury, lovely, gorgeous, epic, cinematic, singular, shining, beautiful, scenic background, bright, awesome, illuminated, amazing, fantastic, wonderful\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, intricate, stunning, highly enhanced, quality, light, color, rich colors, creative, cute, beautiful, elegant, epic, gorgeous, cinematic, dramatic, full focus, bright, sunny, inspired, vibrant, artistic, complex background, open, loving, warm, lovely, exciting, thought, iconic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1024, 1024)\n",
            "Preparation time: 39.00 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "100% 60/60 [00:54<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.20 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 58.47 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "100% 60/60 [00:54<00:00,  1.10it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 57.53 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 116.01 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 155.09 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.97 seconds\n",
            "Loaded preset: /content/Fooocus/presets/pony_v6.json\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/ponyDiffusionV6XL.safetensors\" to /content/Fooocus/models/checkpoints/ponyDiffusionV6XL.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [05:53<00:00, 19.6MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/ponyDiffusionV6XL_vae.safetensors\" to /content/Fooocus/models/vae/ponyDiffusionV6XL_vae.safetensors\n",
            "\n",
            "100% 319M/319M [00:16<00:00, 20.3MB/s]\n",
            "Loaded preset: /content/Fooocus/presets/pony_v6.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6345589051167012818\n",
            "[Parameters] CFG = 7\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "Leftover VAE keys ['model_ema.decay', 'model_ema.num_updates']\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['first_stage_model.decoder.conv_in.bias', 'first_stage_model.decoder.conv_in.weight', 'first_stage_model.decoder.conv_out.bias', 'first_stage_model.decoder.conv_out.weight', 'first_stage_model.decoder.mid.attn_1.k.bias', 'first_stage_model.decoder.mid.attn_1.k.weight', 'first_stage_model.decoder.mid.attn_1.norm.bias', 'first_stage_model.decoder.mid.attn_1.norm.weight', 'first_stage_model.decoder.mid.attn_1.proj_out.bias', 'first_stage_model.decoder.mid.attn_1.proj_out.weight', 'first_stage_model.decoder.mid.attn_1.q.bias', 'first_stage_model.decoder.mid.attn_1.q.weight', 'first_stage_model.decoder.mid.attn_1.v.bias', 'first_stage_model.decoder.mid.attn_1.v.weight', 'first_stage_model.decoder.mid.block_1.conv1.bias', 'first_stage_model.decoder.mid.block_1.conv1.weight', 'first_stage_model.decoder.mid.block_1.conv2.bias', 'first_stage_model.decoder.mid.block_1.conv2.weight', 'first_stage_model.decoder.mid.block_1.norm1.bias', 'first_stage_model.decoder.mid.block_1.norm1.weight', 'first_stage_model.decoder.mid.block_1.norm2.bias', 'first_stage_model.decoder.mid.block_1.norm2.weight', 'first_stage_model.decoder.mid.block_2.conv1.bias', 'first_stage_model.decoder.mid.block_2.conv1.weight', 'first_stage_model.decoder.mid.block_2.conv2.bias', 'first_stage_model.decoder.mid.block_2.conv2.weight', 'first_stage_model.decoder.mid.block_2.norm1.bias', 'first_stage_model.decoder.mid.block_2.norm1.weight', 'first_stage_model.decoder.mid.block_2.norm2.bias', 'first_stage_model.decoder.mid.block_2.norm2.weight', 'first_stage_model.decoder.norm_out.bias', 'first_stage_model.decoder.norm_out.weight', 'first_stage_model.decoder.up.0.block.0.conv1.bias', 'first_stage_model.decoder.up.0.block.0.conv1.weight', 'first_stage_model.decoder.up.0.block.0.conv2.bias', 'first_stage_model.decoder.up.0.block.0.conv2.weight', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.0.block.0.norm1.bias', 'first_stage_model.decoder.up.0.block.0.norm1.weight', 'first_stage_model.decoder.up.0.block.0.norm2.bias', 'first_stage_model.decoder.up.0.block.0.norm2.weight', 'first_stage_model.decoder.up.0.block.1.conv1.bias', 'first_stage_model.decoder.up.0.block.1.conv1.weight', 'first_stage_model.decoder.up.0.block.1.conv2.bias', 'first_stage_model.decoder.up.0.block.1.conv2.weight', 'first_stage_model.decoder.up.0.block.1.norm1.bias', 'first_stage_model.decoder.up.0.block.1.norm1.weight', 'first_stage_model.decoder.up.0.block.1.norm2.bias', 'first_stage_model.decoder.up.0.block.1.norm2.weight', 'first_stage_model.decoder.up.0.block.2.conv1.bias', 'first_stage_model.decoder.up.0.block.2.conv1.weight', 'first_stage_model.decoder.up.0.block.2.conv2.bias', 'first_stage_model.decoder.up.0.block.2.conv2.weight', 'first_stage_model.decoder.up.0.block.2.norm1.bias', 'first_stage_model.decoder.up.0.block.2.norm1.weight', 'first_stage_model.decoder.up.0.block.2.norm2.bias', 'first_stage_model.decoder.up.0.block.2.norm2.weight', 'first_stage_model.decoder.up.1.block.0.conv1.bias', 'first_stage_model.decoder.up.1.block.0.conv1.weight', 'first_stage_model.decoder.up.1.block.0.conv2.bias', 'first_stage_model.decoder.up.1.block.0.conv2.weight', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.1.block.0.norm1.bias', 'first_stage_model.decoder.up.1.block.0.norm1.weight', 'first_stage_model.decoder.up.1.block.0.norm2.bias', 'first_stage_model.decoder.up.1.block.0.norm2.weight', 'first_stage_model.decoder.up.1.block.1.conv1.bias', 'first_stage_model.decoder.up.1.block.1.conv1.weight', 'first_stage_model.decoder.up.1.block.1.conv2.bias', 'first_stage_model.decoder.up.1.block.1.conv2.weight', 'first_stage_model.decoder.up.1.block.1.norm1.bias', 'first_stage_model.decoder.up.1.block.1.norm1.weight', 'first_stage_model.decoder.up.1.block.1.norm2.bias', 'first_stage_model.decoder.up.1.block.1.norm2.weight', 'first_stage_model.decoder.up.1.block.2.conv1.bias', 'first_stage_model.decoder.up.1.block.2.conv1.weight', 'first_stage_model.decoder.up.1.block.2.conv2.bias', 'first_stage_model.decoder.up.1.block.2.conv2.weight', 'first_stage_model.decoder.up.1.block.2.norm1.bias', 'first_stage_model.decoder.up.1.block.2.norm1.weight', 'first_stage_model.decoder.up.1.block.2.norm2.bias', 'first_stage_model.decoder.up.1.block.2.norm2.weight', 'first_stage_model.decoder.up.1.upsample.conv.bias', 'first_stage_model.decoder.up.1.upsample.conv.weight', 'first_stage_model.decoder.up.2.block.0.conv1.bias', 'first_stage_model.decoder.up.2.block.0.conv1.weight', 'first_stage_model.decoder.up.2.block.0.conv2.bias', 'first_stage_model.decoder.up.2.block.0.conv2.weight', 'first_stage_model.decoder.up.2.block.0.norm1.bias', 'first_stage_model.decoder.up.2.block.0.norm1.weight', 'first_stage_model.decoder.up.2.block.0.norm2.bias', 'first_stage_model.decoder.up.2.block.0.norm2.weight', 'first_stage_model.decoder.up.2.block.1.conv1.bias', 'first_stage_model.decoder.up.2.block.1.conv1.weight', 'first_stage_model.decoder.up.2.block.1.conv2.bias', 'first_stage_model.decoder.up.2.block.1.conv2.weight', 'first_stage_model.decoder.up.2.block.1.norm1.bias', 'first_stage_model.decoder.up.2.block.1.norm1.weight', 'first_stage_model.decoder.up.2.block.1.norm2.bias', 'first_stage_model.decoder.up.2.block.1.norm2.weight', 'first_stage_model.decoder.up.2.block.2.conv1.bias', 'first_stage_model.decoder.up.2.block.2.conv1.weight', 'first_stage_model.decoder.up.2.block.2.conv2.bias', 'first_stage_model.decoder.up.2.block.2.conv2.weight', 'first_stage_model.decoder.up.2.block.2.norm1.bias', 'first_stage_model.decoder.up.2.block.2.norm1.weight', 'first_stage_model.decoder.up.2.block.2.norm2.bias', 'first_stage_model.decoder.up.2.block.2.norm2.weight', 'first_stage_model.decoder.up.2.upsample.conv.bias', 'first_stage_model.decoder.up.2.upsample.conv.weight', 'first_stage_model.decoder.up.3.block.0.conv1.bias', 'first_stage_model.decoder.up.3.block.0.conv1.weight', 'first_stage_model.decoder.up.3.block.0.conv2.bias', 'first_stage_model.decoder.up.3.block.0.conv2.weight', 'first_stage_model.decoder.up.3.block.0.norm1.bias', 'first_stage_model.decoder.up.3.block.0.norm1.weight', 'first_stage_model.decoder.up.3.block.0.norm2.bias', 'first_stage_model.decoder.up.3.block.0.norm2.weight', 'first_stage_model.decoder.up.3.block.1.conv1.bias', 'first_stage_model.decoder.up.3.block.1.conv1.weight', 'first_stage_model.decoder.up.3.block.1.conv2.bias', 'first_stage_model.decoder.up.3.block.1.conv2.weight', 'first_stage_model.decoder.up.3.block.1.norm1.bias', 'first_stage_model.decoder.up.3.block.1.norm1.weight', 'first_stage_model.decoder.up.3.block.1.norm2.bias', 'first_stage_model.decoder.up.3.block.1.norm2.weight', 'first_stage_model.decoder.up.3.block.2.conv1.bias', 'first_stage_model.decoder.up.3.block.2.conv1.weight', 'first_stage_model.decoder.up.3.block.2.conv2.bias', 'first_stage_model.decoder.up.3.block.2.conv2.weight', 'first_stage_model.decoder.up.3.block.2.norm1.bias', 'first_stage_model.decoder.up.3.block.2.norm1.weight', 'first_stage_model.decoder.up.3.block.2.norm2.bias', 'first_stage_model.decoder.up.3.block.2.norm2.weight', 'first_stage_model.decoder.up.3.upsample.conv.bias', 'first_stage_model.decoder.up.3.upsample.conv.weight', 'first_stage_model.encoder.conv_in.bias', 'first_stage_model.encoder.conv_in.weight', 'first_stage_model.encoder.conv_out.bias', 'first_stage_model.encoder.conv_out.weight', 'first_stage_model.encoder.down.0.block.0.conv1.bias', 'first_stage_model.encoder.down.0.block.0.conv1.weight', 'first_stage_model.encoder.down.0.block.0.conv2.bias', 'first_stage_model.encoder.down.0.block.0.conv2.weight', 'first_stage_model.encoder.down.0.block.0.norm1.bias', 'first_stage_model.encoder.down.0.block.0.norm1.weight', 'first_stage_model.encoder.down.0.block.0.norm2.bias', 'first_stage_model.encoder.down.0.block.0.norm2.weight', 'first_stage_model.encoder.down.0.block.1.conv1.bias', 'first_stage_model.encoder.down.0.block.1.conv1.weight', 'first_stage_model.encoder.down.0.block.1.conv2.bias', 'first_stage_model.encoder.down.0.block.1.conv2.weight', 'first_stage_model.encoder.down.0.block.1.norm1.bias', 'first_stage_model.encoder.down.0.block.1.norm1.weight', 'first_stage_model.encoder.down.0.block.1.norm2.bias', 'first_stage_model.encoder.down.0.block.1.norm2.weight', 'first_stage_model.encoder.down.0.downsample.conv.bias', 'first_stage_model.encoder.down.0.downsample.conv.weight', 'first_stage_model.encoder.down.1.block.0.conv1.bias', 'first_stage_model.encoder.down.1.block.0.conv1.weight', 'first_stage_model.encoder.down.1.block.0.conv2.bias', 'first_stage_model.encoder.down.1.block.0.conv2.weight', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.1.block.0.norm1.bias', 'first_stage_model.encoder.down.1.block.0.norm1.weight', 'first_stage_model.encoder.down.1.block.0.norm2.bias', 'first_stage_model.encoder.down.1.block.0.norm2.weight', 'first_stage_model.encoder.down.1.block.1.conv1.bias', 'first_stage_model.encoder.down.1.block.1.conv1.weight', 'first_stage_model.encoder.down.1.block.1.conv2.bias', 'first_stage_model.encoder.down.1.block.1.conv2.weight', 'first_stage_model.encoder.down.1.block.1.norm1.bias', 'first_stage_model.encoder.down.1.block.1.norm1.weight', 'first_stage_model.encoder.down.1.block.1.norm2.bias', 'first_stage_model.encoder.down.1.block.1.norm2.weight', 'first_stage_model.encoder.down.1.downsample.conv.bias', 'first_stage_model.encoder.down.1.downsample.conv.weight', 'first_stage_model.encoder.down.2.block.0.conv1.bias', 'first_stage_model.encoder.down.2.block.0.conv1.weight', 'first_stage_model.encoder.down.2.block.0.conv2.bias', 'first_stage_model.encoder.down.2.block.0.conv2.weight', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.2.block.0.norm1.bias', 'first_stage_model.encoder.down.2.block.0.norm1.weight', 'first_stage_model.encoder.down.2.block.0.norm2.bias', 'first_stage_model.encoder.down.2.block.0.norm2.weight', 'first_stage_model.encoder.down.2.block.1.conv1.bias', 'first_stage_model.encoder.down.2.block.1.conv1.weight', 'first_stage_model.encoder.down.2.block.1.conv2.bias', 'first_stage_model.encoder.down.2.block.1.conv2.weight', 'first_stage_model.encoder.down.2.block.1.norm1.bias', 'first_stage_model.encoder.down.2.block.1.norm1.weight', 'first_stage_model.encoder.down.2.block.1.norm2.bias', 'first_stage_model.encoder.down.2.block.1.norm2.weight', 'first_stage_model.encoder.down.2.downsample.conv.bias', 'first_stage_model.encoder.down.2.downsample.conv.weight', 'first_stage_model.encoder.down.3.block.0.conv1.bias', 'first_stage_model.encoder.down.3.block.0.conv1.weight', 'first_stage_model.encoder.down.3.block.0.conv2.bias', 'first_stage_model.encoder.down.3.block.0.conv2.weight', 'first_stage_model.encoder.down.3.block.0.norm1.bias', 'first_stage_model.encoder.down.3.block.0.norm1.weight', 'first_stage_model.encoder.down.3.block.0.norm2.bias', 'first_stage_model.encoder.down.3.block.0.norm2.weight', 'first_stage_model.encoder.down.3.block.1.conv1.bias', 'first_stage_model.encoder.down.3.block.1.conv1.weight', 'first_stage_model.encoder.down.3.block.1.conv2.bias', 'first_stage_model.encoder.down.3.block.1.conv2.weight', 'first_stage_model.encoder.down.3.block.1.norm1.bias', 'first_stage_model.encoder.down.3.block.1.norm1.weight', 'first_stage_model.encoder.down.3.block.1.norm2.bias', 'first_stage_model.encoder.down.3.block.1.norm2.weight', 'first_stage_model.encoder.mid.attn_1.k.bias', 'first_stage_model.encoder.mid.attn_1.k.weight', 'first_stage_model.encoder.mid.attn_1.norm.bias', 'first_stage_model.encoder.mid.attn_1.norm.weight', 'first_stage_model.encoder.mid.attn_1.proj_out.bias', 'first_stage_model.encoder.mid.attn_1.proj_out.weight', 'first_stage_model.encoder.mid.attn_1.q.bias', 'first_stage_model.encoder.mid.attn_1.q.weight', 'first_stage_model.encoder.mid.attn_1.v.bias', 'first_stage_model.encoder.mid.attn_1.v.weight', 'first_stage_model.encoder.mid.block_1.conv1.bias', 'first_stage_model.encoder.mid.block_1.conv1.weight', 'first_stage_model.encoder.mid.block_1.conv2.bias', 'first_stage_model.encoder.mid.block_1.conv2.weight', 'first_stage_model.encoder.mid.block_1.norm1.bias', 'first_stage_model.encoder.mid.block_1.norm1.weight', 'first_stage_model.encoder.mid.block_1.norm2.bias', 'first_stage_model.encoder.mid.block_1.norm2.weight', 'first_stage_model.encoder.mid.block_2.conv1.bias', 'first_stage_model.encoder.mid.block_2.conv1.weight', 'first_stage_model.encoder.mid.block_2.conv2.bias', 'first_stage_model.encoder.mid.block_2.conv2.weight', 'first_stage_model.encoder.mid.block_2.norm1.bias', 'first_stage_model.encoder.mid.block_2.norm1.weight', 'first_stage_model.encoder.mid.block_2.norm2.bias', 'first_stage_model.encoder.mid.block_2.norm2.weight', 'first_stage_model.encoder.norm_out.bias', 'first_stage_model.encoder.norm_out.weight', 'first_stage_model.post_quant_conv.bias', 'first_stage_model.post_quant_conv.weight', 'first_stage_model.quant_conv.bias', 'first_stage_model.quant_conv.weight', 'cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.07 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/ponyDiffusionV6XL.safetensors\n",
            "VAE loaded: /content/Fooocus/models/vae/ponyDiffusionV6XL_vae.safetensors\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/ponyDiffusionV6XL.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 39.11 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "100% 60/60 [00:51<00:00,  1.17it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Saving image 1/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 55.05 seconds\n",
            "[Fooocus] Preparing task 2/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "100% 60/60 [00:51<00:00,  1.18it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Saving image 2/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 54.01 seconds\n",
            "[Fooocus] Preparing task 3/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "100% 60/60 [00:51<00:00,  1.17it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Saving image 3/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 54.08 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 163.14 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 202.31 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.99 seconds\n",
            "Loaded preset: /content/Fooocus/presets/lightning.json\n",
            "Enter Lightning mode.\n",
            "[Fooocus] Downloading Lightning components ...\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/sdxl_lightning_4step_lora.safetensors\" to /content/Fooocus/models/loras/sdxl_lightning_4step_lora.safetensors\n",
            "\n",
            "100% 376M/376M [00:22<00:00, 17.5MB/s]\n",
            "[Parameters] Adaptive CFG = 1.0\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 0.0\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.0 : 1.0 : 0.0\n",
            "[Parameters] Seed = 1239236955066243082\n",
            "[Parameters] CFG = 1.0\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = euler - sgm_uniform\n",
            "[Parameters] Steps = 4 - 4\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.10 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sdxl_lightning_4step_lora.safetensors', 1.0)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sdxl_lightning_4step_lora.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 1.0.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, intricate, extremely detailed, elegant, highly connected, sacred, holy, enigmatic, cute, magical, glowing, light, beautiful, sharp focus, stunning, attractive, futuristic, bright background, open dynamic deep color, epic dramatic ambient, creative, cinematic, pure, amazing, gorgeous, breathtaking, thought, elite, mystical\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, cute, intricate, stunning, highly enhanced, amazing, attractive, delicate, creative, beautiful, elegant, fancy, epic, best, surreal, dramatic ambient light, magical, sharp focus, professional, cinematic, artistic, thought, iconic, cool, incredible, marvelous, fabulous, colossal, exquisite detail\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 65.82 seconds\n",
            "Using sgm_uniform scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.6951494216918945, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.76 seconds\n",
            "100% 4/4 [00:01<00:00,  2.24it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 6.43 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.6951494216918945, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "100% 4/4 [00:01<00:00,  2.21it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 5.43 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 11.86 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 77.71 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.91 seconds\n",
            "Enter Lightning mode.\n",
            "[Fooocus] Downloading Lightning components ...\n",
            "[Parameters] Adaptive CFG = 1.0\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 0.0\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.0 : 1.0 : 0.0\n",
            "[Parameters] Seed = 9183452717532097541\n",
            "[Parameters] CFG = 1.0\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = euler - sgm_uniform\n",
            "[Parameters] Steps = 4 - 4\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, intricate, stunning, highly enhanced, intense light, real, rich colors, magical, mystical background, holy surreal, dramatic cinematic atmosphere, sharp focus, epic breathtaking artistic, thought, elite, colorful, deep vivid, astonishing, creative, elegant,, beautiful, attractive, cute, best, adorable, futuristic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, intricate, stunning, highly advanced, artistic, illustrious, fine detail, real, cute, magical, delicate, sharp focus, divine holy light, dramatic cinematic, great composition, elegant, rich deep colors, beautiful scenic background, ambient, epic, shining, brilliant, supreme quality, creative, positive spiritual\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 1.90 seconds\n",
            "Using sgm_uniform scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.6951494216918945, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.32 seconds\n",
            "100% 4/4 [00:01<00:00,  2.24it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 6.06 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.6951494216918945, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            "100% 4/4 [00:01<00:00,  2.19it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 5.49 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 11.55 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 13.48 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Enter Lightning mode.\n",
            "[Fooocus] Downloading Lightning components ...\n",
            "[Parameters] Adaptive CFG = 1.0\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 0.0\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.0 : 1.0 : 0.0\n",
            "[Parameters] Seed = 9045160821188837477\n",
            "[Parameters] CFG = 1.0\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = euler - sgm_uniform\n",
            "[Parameters] Steps = 4 - 4\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, intricate, stunning, highly, divine holy light, creative, shining, glowing, sharp focus, heavenly atmosphere, beautiful, cute, delicate, elegant, marvelous, luxury, elite, colorful background, ambient dramatic cinematic color, epic composition, inspirational, sublime, vibrant colors, radiant, magical, rich deep vivid\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, intricate, stunning, highly enhanced quality, light surreal color, holy sacred, scenic, lush, attractive, bright, magical, sharp focus, professional, smart, best, cute, artistic, beautiful, dramatic, pure, aesthetic, cool, shiny, epic, awesome, gorgeous, amazing, breathtaking background\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 1.87 seconds\n",
            "Using sgm_uniform scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.6951494216918945, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.27 seconds\n",
            "100% 4/4 [00:01<00:00,  2.20it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.31 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 6.00 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.6951494216918945, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.71 seconds\n",
            "100% 4/4 [00:01<00:00,  2.21it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 5.38 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 11.38 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 13.28 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8507348107629908036\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.36 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, extremely detailed, intricate, stunning, highly enhanced quality, light, color, magical, deep aesthetic, lush scenic background, thought, singular, romantic, holy, divine, elegant, sharp focus, professional creative, cute, attractive, sublime, smart, best, appealing, beautiful, dramatic, bright colors, shiny, fine\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] sexy pink harness, pink bondage garment, naked model, pretty naked boobs, nipples, nude, circular tits, big and hard nipples, biggest chest, perfect boobs, strict training, chains, obedient woman, extreme submission, slavery, restriction, very tight pink latex, dildo, high definition, bra over boobs, xxx, porn, picture, porn scene, porn tits, porn boobs, porn girl, porn garments, revealing, extremely detailed, beautiful, intricate, stunning, highly advanced, sophisticated, delicate, creative, cute, fashionable, elegant, gorgeous, amazing, cool, futuristic, inspiring, vibrant, glowing, sharp focus, expressive, attractive, bright colors, winning, romantic, sublime, iconic, fine detail, full color\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 3.61 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "100% 60/60 [00:56<00:00,  1.07it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 59.87 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "100% 60/60 [00:55<00:00,  1.08it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-03-19/log.html\n",
            "Generating and saving time: 58.42 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 118.29 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 121.95 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}